{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhwans/rhwans/blob/main/NLP_%EB%B2%84%ED%86%A0%ED%94%BD(BERTopic).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O6k7dCGZFEWE",
        "outputId": "196c818c-7294-4726-db12-1c67fc154d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "E: Package 'python-dev' has no installation candidate\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Requirement already satisfied: python-mecab-ko in /usr/local/lib/python3.11/dist-packages (1.3.7)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.11/dist-packages (from python-mecab-ko) (2.1.1.post2)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (3.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.51.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.1.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.1.31)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: bertopic[visualization] in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "\u001b[33mWARNING: bertopic 0.17.0 does not provide the extra 'visualization'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (3.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic[visualization]) (0.5.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic[visualization]) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic[visualization]) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic[visualization]) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (4.51.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (11.1.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (4.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic[visualization]) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic[visualization]) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2025.1.31)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# 필요한 패키지 설치\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq g++ openjdk-8-jdk python-dev python3-dev\n",
        "!pip install konlpy\n",
        "!pip install python-mecab-ko\n",
        "!pip install mecab-python3\n",
        "!pip install bertopic plotly\n",
        "!pip install bertopic[visualization] plotly\n",
        "!pip install wordcloud networkx matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZEh8f8vCwOX"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from konlpy.tag import Mecab\n",
        "from bertopic import BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uRnqM2THLD1f",
        "outputId": "5f675465-4fbb-4d6c-b0cd-358e3803a8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mecab-python3==0.996.5\n",
            "  Using cached mecab-python3-0.996.5.tar.gz (65 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2025-04-17 05:51:31--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 13.200.41.136, 13.200.41.135, 13.200.41.134, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|13.200.41.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNOFW3XI5A&Signature=PDLmafRtqAsxQNWr8uvBf6SKu98%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGo7Vdy4T2R5ique5ZfhPf4ukDw7MSqdJ9MOvjzRouccAiEAl5Gdu5chtX3FMNhleMAbQ0ef4k3yfoUHB2gJoz90LCoqpwIIVxAAGgw5ODQ1MjUxMDExNDYiDEEYGj9glHdVoWlQESqEAuKkDY0fZhc0x1cgTNFPnuMPU8CMCd2BFKIdsGsgHl9e6CDRKHBYYj5riPckYnInX1gfwzuZuK4jS189f%2BXFtZksAR2%2FKTTVUIdAhJHr2Rgi7Sq5PQWcaCHWnOynykte3JcYjdrkuORPVBcZBpmQu8P9HnDZYkFl3%2BlL7sdSi%2BFLJE%2BnHlO4LxWmRntlXxV49bDLTzbMzSvB3iUrCgQ0GNNOOPqr6t1klQYwQctTGIQG89gYjIAdfxl9FYwVX0udxWGX1qGraJ0%2BXI10UI5I3lK%2FhBDaYEudkTg1W5lifqpq1viSQwwtpmpCLP8YQtyoXdZ1C%2B0NzwI6xK4%2FIMCKZYIAE37jMNaqgsAGOp0Bv9vm%2FIB9Juqb8HkOwxR94flfnqB%2BY8nwsloXQ1Q4o6KF6TaZKJ%2FrnYfq7iBn2sbElLLlCW%2Bk%2Bkdqu76sYo%2FGcIZJpiV7Fy%2FYItxNhS5Bd1i7uF2gA3GIBCDdCxVN8fk3xBD7mp%2BjHb0mGUduWTw%2BNsJuHN4O994pqPsbdyCNSxhroqlv4dLty7Qk1nx9VFH7ABYUxCLfShBz9W8cZw%3D%3D&Expires=1744870494 [following]\n",
            "--2025-04-17 05:51:31--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNOFW3XI5A&Signature=PDLmafRtqAsxQNWr8uvBf6SKu98%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGo7Vdy4T2R5ique5ZfhPf4ukDw7MSqdJ9MOvjzRouccAiEAl5Gdu5chtX3FMNhleMAbQ0ef4k3yfoUHB2gJoz90LCoqpwIIVxAAGgw5ODQ1MjUxMDExNDYiDEEYGj9glHdVoWlQESqEAuKkDY0fZhc0x1cgTNFPnuMPU8CMCd2BFKIdsGsgHl9e6CDRKHBYYj5riPckYnInX1gfwzuZuK4jS189f%2BXFtZksAR2%2FKTTVUIdAhJHr2Rgi7Sq5PQWcaCHWnOynykte3JcYjdrkuORPVBcZBpmQu8P9HnDZYkFl3%2BlL7sdSi%2BFLJE%2BnHlO4LxWmRntlXxV49bDLTzbMzSvB3iUrCgQ0GNNOOPqr6t1klQYwQctTGIQG89gYjIAdfxl9FYwVX0udxWGX1qGraJ0%2BXI10UI5I3lK%2FhBDaYEudkTg1W5lifqpq1viSQwwtpmpCLP8YQtyoXdZ1C%2B0NzwI6xK4%2FIMCKZYIAE37jMNaqgsAGOp0Bv9vm%2FIB9Juqb8HkOwxR94flfnqB%2BY8nwsloXQ1Q4o6KF6TaZKJ%2FrnYfq7iBn2sbElLLlCW%2Bk%2Bkdqu76sYo%2FGcIZJpiV7Fy%2FYItxNhS5Bd1i7uF2gA3GIBCDdCxVN8fk3xBD7mp%2BjHb0mGUduWTw%2BNsJuHN4O994pqPsbdyCNSxhroqlv4dLty7Qk1nx9VFH7ABYUxCLfShBz9W8cZw%3D%3D&Expires=1744870494\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 16.182.98.81, 16.182.100.129, 3.5.30.51, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|16.182.98.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.04MB/s    in 1.3s    \n",
            "\n",
            "2025-04-17 05:51:33 (1.04 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2025-04-17 05:51:46--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 13.200.41.136, 13.200.41.135, 13.200.41.134, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|13.200.41.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKKHBIPAX&Signature=%2Bq%2FXLA9YREBkE%2FOlWf531H16LBI%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBqLX040PEC5zjcfbP9vH2e0J17o8e3t3yojRUJc9L2WAiEA2F%2BNq3L%2FVHFibF6f2ua0nyorZh7M2y%2B2pJNAk280DHcqpwIIVxAAGgw5ODQ1MjUxMDExNDYiDMRhaQM4G%2FLNCkp3MyqEAhV5l7RIVWpduUvCSTePxErdMYZW%2Fgv0ehv5cZehOK8hJ%2FPHbKYc1iW3bow%2B5qXiGW9c5%2BZPrt5cTNwGYgrcAbtHfgHX6bHPSe6J%2BwX7WAGKs3f9u157HeYl9p%2FZRcOxgKvH8TUdsWSga2WhuiXScqo2D5okecMF4czVghXY2%2B0IWlJZmhl33KlmF1a1UM0HLGgy%2BsBA9RjzSlSMeEmo3tKHb4MsglLVYcj8olnFp%2FGR15VmMVnaJ%2F8VmDoMZ2BsrZD4hkV80JCCqakEUOj8Sjy%2Ffs0DVecoFnUZveANO9jOVl4GbSvPGiR%2Fy9L3ThsmO0O7%2BuU33m%2Bel61Cix8QA842bBqgMNWqgsAGOp0BmnQ%2FGgYTV2oaohXp4yGcJ6jBoJkpixBK1Cdw1AMsWZYc62bxCd27%2Bn%2BS92sruLUgdwsMZ0p1Qwq%2FSmu1%2Fys4UhQsRT5vPwvI1CRXsbQqh%2Fv%2F%2BSHQ3UH6dcWNOCySPhG%2FB8E%2BlhWO3FUbExGakWU5cOWWbZIX8HGFhbIxuj8MfZFXetL%2BxuILHJif6eS227NBT7vbtRr6AEJrHaHACQ%3D%3D&Expires=1744870493 [following]\n",
            "--2025-04-17 05:51:46--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKKHBIPAX&Signature=%2Bq%2FXLA9YREBkE%2FOlWf531H16LBI%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBqLX040PEC5zjcfbP9vH2e0J17o8e3t3yojRUJc9L2WAiEA2F%2BNq3L%2FVHFibF6f2ua0nyorZh7M2y%2B2pJNAk280DHcqpwIIVxAAGgw5ODQ1MjUxMDExNDYiDMRhaQM4G%2FLNCkp3MyqEAhV5l7RIVWpduUvCSTePxErdMYZW%2Fgv0ehv5cZehOK8hJ%2FPHbKYc1iW3bow%2B5qXiGW9c5%2BZPrt5cTNwGYgrcAbtHfgHX6bHPSe6J%2BwX7WAGKs3f9u157HeYl9p%2FZRcOxgKvH8TUdsWSga2WhuiXScqo2D5okecMF4czVghXY2%2B0IWlJZmhl33KlmF1a1UM0HLGgy%2BsBA9RjzSlSMeEmo3tKHb4MsglLVYcj8olnFp%2FGR15VmMVnaJ%2F8VmDoMZ2BsrZD4hkV80JCCqakEUOj8Sjy%2Ffs0DVecoFnUZveANO9jOVl4GbSvPGiR%2Fy9L3ThsmO0O7%2BuU33m%2Bel61Cix8QA842bBqgMNWqgsAGOp0BmnQ%2FGgYTV2oaohXp4yGcJ6jBoJkpixBK1Cdw1AMsWZYc62bxCd27%2Bn%2BS92sruLUgdwsMZ0p1Qwq%2FSmu1%2Fys4UhQsRT5vPwvI1CRXsbQqh%2Fv%2F%2BSHQ3UH6dcWNOCySPhG%2FB8E%2BlhWO3FUbExGakWU5cOWWbZIX8HGFhbIxuj8MfZFXetL%2BxuILHJif6eS227NBT7vbtRr6AEJrHaHACQ%3D%3D&Expires=1744870493\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 3.5.27.207, 52.216.212.153, 52.217.228.153, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|3.5.27.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  11.0MB/s    in 4.5s    \n",
            "\n",
            "2025-04-17 05:51:52 (10.5 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ],
      "source": [
        "# MeCab 한국어 사전 설치\n",
        "!apt-get install -qq mecab libmecab-dev mecab-ipadic-utf8\n",
        "!pip install mecab-python3==0.996.5\n",
        "!git clone --depth 1 https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "!bash Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab190912.sh\n",
        "\n",
        "# MeCab 환경 변수 설정 (Colab 환경에서 필요)\n",
        "os.environ['MECAB_CONFIG'] = '/usr/local/etc/mecabrc'  # mecabrc 파일 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ilXoEPpIIQd8",
        "outputId": "6b8285ea-adbd-4883-89a5-10d95ef54822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mecab\tSL,*,*,*,*,*,*,*\n",
            "-\tSY,*,*,*,*,*,*,*\n",
            "python\tSL,*,*,*,*,*,*,*\n",
            "3\tSN,*,*,*,*,*,*,*\n",
            "설치\tNNG,행위,F,설치,*,*,*,*\n",
            "테스트\tNNG,행위,F,테스트,*,*,*,*\n",
            "EOS\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MeCab 테스트\n",
        "import MeCab\n",
        "mecab = MeCab.Tagger()\n",
        "print(mecab.parse(\"mecab-python3 설치 테스트\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbKCFYFN-k2W"
      },
      "outputs": [],
      "source": [
        "# 텍스트 클렌징 함수\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = re.sub(r'[0-9]+[a-zA-Z]*', '', text)  # 숫자 + 영어 조합 제거 (예: 40up, 10km 등)\n",
        "    text = re.sub(r'[a-zA-Z]+', '', text)        # 영어 제거\n",
        "    text = re.sub(r'[^가-힣\\s]', '', text)        # 한글 + 공백만 유지\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# 유사어 처리기 클래스\n",
        "class SynonymProcessor:\n",
        "    def __init__(self):\n",
        "        self.synonym_dict = {\n",
        "            # 스탬프 관련\n",
        "            '스탬프': ['도장', '스템프', '스탬프인증', '스탬프확인', '도장찍기', '스탬프투어'],\n",
        "            '배지': ['배찌', '뱃지', '뱃찌', '기념배지'],\n",
        "            # 보상 관련\n",
        "            '보상': ['리워드', '상품', '상금', '포인트'],\n",
        "            '선물': ['기념품', '증정품', '사은품', '기념선물', '기념메달'],\n",
        "            # 장소/활동 관련\n",
        "            '둘레길': ['둘레길코스', '트레킹코스', '산책로', '둘레'],\n",
        "            '걷기': ['워킹', '하이킹', '트레킹', '산책'],\n",
        "            '인증': ['체크', '확인', '인증샷', '인증도장'],\n",
        "            '참여': ['참가', '등록', '신청', '접수'],\n",
        "            '완주': ['완료', '종료', '마무리', '완보'],\n",
        "            # 복합 키워드 통합\n",
        "            '호미해안': ['호미 해안', '해안 호미', '호미', '해안'],\n",
        "            '해안둘레길': ['해안 둘레길', '호미 둘레길', '호미해안길'],\n",
        "            '하늘공원': ['하늘 공원', '공원 하늘', '하늘공원'],\n",
        "            '숲길': ['숲길', '산림길', '자연길', '숲 체험로'],\n",
        "            '원도심': ['구도심', '도심지', '원도심'],\n",
        "            '정상': ['정상', '정상도'],\n",
        "            '청소년': ['청소년', '청소년단', '청소년들'],\n",
        "            '리버': ['리버', '러브리버', '러버'],\n",
        "            '드론촬영': ['드론 촬영', '드론촬영', '항공촬영', '항공 촬영'],\n",
        "            '영상촬영': ['영상촬영', '영상 촬영', '촬영영상'],\n",
        "            '청산도': ['청산도', '청산']\n",
        "        }\n",
        "\n",
        "        self.reverse_mapping = {}\n",
        "        for standard, synonyms in self.synonym_dict.items():\n",
        "            for synonym in synonyms:\n",
        "                self.reverse_mapping[synonym] = standard\n",
        "            self.reverse_mapping[standard] = standard\n",
        "\n",
        "    def standardize_text(self, text):\n",
        "        if not isinstance(text, str):\n",
        "            return text\n",
        "        words = text.split()\n",
        "        return ' '.join([self.reverse_mapping.get(word, word) for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCqtX_i1BxQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "b7351dc1-f253-47c4-9c01-5ac1d3e2cc4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28255372-48e9-4786-852a-e9e8c10ce2a9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28255372-48e9-4786-852a-e9e8c10ce2a9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 걷기축제_통합_LDA강조.csv to 걷기축제_통합_LDA강조.csv\n"
          ]
        }
      ],
      "source": [
        "# CSV 파일 업로드\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "df = pd.read_csv('걷기축제_통합_LDA강조.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KScCSk9bBxN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab3d802-f035-4be7-81d2-306f39af957f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7665/7665 [00:00<00:00, 46311.68it/s]\n"
          ]
        }
      ],
      "source": [
        "# 'text' 열에서 데이터 추출 및 전처리\n",
        "preprocessed_documents = []\n",
        "for line in tqdm(df['내용']):\n",
        " # 빈 문자열이거나 숫자로만 이루어진 줄은 제외\n",
        "  if isinstance(line, str) and line and not line.replace(' ', '').isdecimal():\n",
        "    preprocessed_documents.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5xX_j-W-zbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0feb4438-810f-4949-a6e8-447d7991d32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7665/7665 [00:00<00:00, 7686.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리된 문서 수: 7665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 유사어 처리기 적용\n",
        "synonym_processor = SynonymProcessor()\n",
        "preprocessed_documents = []\n",
        "for line in tqdm(df['내용']):\n",
        "    if isinstance(line, str) and line and not line.replace(' ', '').isdecimal():\n",
        "        processed_line = synonym_processor.standardize_text(line)\n",
        "        preprocessed_documents.append(processed_line)\n",
        "\n",
        "print(f\"전처리된 문서 수: {len(preprocessed_documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usCNVFo_BxF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b217d159-766d-4963-c5d7-f57e293afaed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 필터링된 문장 수: 7609\n"
          ]
        }
      ],
      "source": [
        "#커스텀 토크나이저 정의\n",
        "# 1. 토큰화 개선\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, tagger):\n",
        "        self.tagger = tagger\n",
        "    def __call__(self, sent):\n",
        "        sent = sent[:100000]\n",
        "        nodes = self.tagger.parseToNode(sent)\n",
        "        word_tokens = []\n",
        "        while nodes:\n",
        "            pos = nodes.feature.split(',')[0]  # 품사 정보 추출\n",
        "            word = nodes.surface\n",
        "            # 명사, 동사, 형용사만 선택적으로 추출\n",
        "            if pos in ['NNG', 'NNP', 'VV', 'VA'] and len(word) > 1:\n",
        "                word_tokens.append(word)\n",
        "            nodes = nodes.next\n",
        "        return word_tokens\n",
        "\n",
        "custom_tokenizer = CustomTokenizer(MeCab.Tagger())\n",
        "\n",
        "# 개념 키워드 기반 중요 키워드 설정\n",
        "# 6개 개념 키워드 정의\n",
        "concept_keywords_extended = {\n",
        "    \"일탈성\": [\"일탈\", \"자유\", \"해방\", \"비일상\", \"탈출\", \"이색\", \"새로움\", \"도전\", \"낯선\", \"탈출구\"],\n",
        "    \"놀이성\": [\"놀이\", \"즐기\", \"재미\", \"체험\", \"놀다\", \"이벤트\", \"축제\", \"즐거움\", \"오락\", \"게임\"],\n",
        "    \"대동성\": [\"함께\", \"가족\", \"친구\", \"연대\", \"모두\", \"공감\", \"공동\", \"동행\", \"집단\", \"참여\"],\n",
        "    \"장소성\": [\"장소\", \"장터\", \"거리\", \"공간\", \"현장\", \"지역\", \"마을\", \"구간\", \"코스\", \"포인트\", \"명소\", \"길\"],\n",
        "    \"성취감\": [\"완주\", \"인증\", \"스탬프\", \"배지\", \"보상\", \"성공\", \"도전\", \"획득\", \"달성\", \"선물\"],\n",
        "    \"회복성\": [\"회복\", \"힐링\", \"치유\", \"휴식\", \"쉼\", \"재충전\", \"편안함\", \"명상\", \"안정감\", \"여유\"]\n",
        "}\n",
        "\n",
        "important_keywords = list(set(sum(concept_keywords_extended.values(), [])))\n",
        "\n",
        "# 전체 키워드 모으기\n",
        "all_keywords = set(sum(concept_keywords_extended.values(), []))\n",
        "\n",
        "# 전처리된 문서 리스트가 없다면 생성\n",
        "if 'preprocessed_documents' not in locals():\n",
        "    synonym_processor = SynonymProcessor()\n",
        "    preprocessed_documents = []\n",
        "    for line in df['내용']:\n",
        "        if isinstance(line, str) and line and not line.replace(' ', '').isdecimal():\n",
        "            processed_line = synonym_processor.standardize_text(line)\n",
        "            preprocessed_documents.append(processed_line)\n",
        "\n",
        "# 개념 키워드가 포함된 문장만 추출\n",
        "filtered_docs = [doc for doc in preprocessed_documents if any(keyword in doc for keyword in all_keywords)]\n",
        "\n",
        "print(f\"총 필터링된 문장 수: {len(filtered_docs)}\")\n",
        "\n",
        "# 불용어 처리 및 vectorizer 설정\n",
        "korean_stop_words = ['크롤링', '취소', '실패', '본문', '출처', '15', '11', '14', 'kg', '20', 'km',\n",
        "'....', '12', '16', '2015', '00', '13', '09', '10', '~^^', '30', 'ㅋㅋ', '까지', '^^', '네요', '해요', 'ㅎㅎ', 'ㅇㅇ', '!!', '아요',\n",
        "'ㅋㅋㅋ', '...', '..', '셔서', '라는', '있다', '하다', '되다', '이다', '도', '만',\n",
        "'것', '수', '등', '를', '을', '에', '에서', '의', '습니다', '는데', '너무', '어요', '입니다',\n",
        "'으로', '어서', '라서', '지만', '합니다', '정말', '에게', '갑니다', '없이', '다는', '면서',\n",
        "'페이지 이동', '페이지', '장길자', '회장']\n",
        "\n",
        "# 중요 키워드 다시 포함\n",
        "korean_stop_words = [word for word in korean_stop_words if word not in important_keywords]\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    tokenizer=custom_tokenizer,\n",
        "    max_features=3000,\n",
        "    stop_words=korean_stop_words,\n",
        "    ngram_range=(1, 1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdA5MlO3B4Rz"
      },
      "outputs": [],
      "source": [
        "#BERTopic 모델 설정 및 학습\n",
        "MODEL_NAME = \"sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\"\n",
        "model = BERTopic(\n",
        "    embedding_model=MODEL_NAME,\n",
        "    vectorizer_model=vectorizer,\n",
        "    nr_topics=None,  # 토픽 수 병합 없이 모두 유지\n",
        "    min_topic_size=5,  # 토픽 최소 문서 수 줄이기\n",
        "    top_n_words=5,\n",
        "    calculate_probabilities=True,\n",
        ")\n",
        "topics, probs = model.fit_transform(preprocessed_documents)\n",
        "\n",
        "\n",
        "# 딱 20개의 토픽으로 정제\n",
        "model = model.reduce_topics(preprocessed_documents, nr_topics=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wyhaU0qqCR8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74645482-a887-4489-f2e3-b6af27d6c3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Topic  Count                Name              Representation  \\\n",
            "0      -1   3825      -1_부산_코스_국제_대회        [부산, 코스, 국제, 대회, 구간]   \n",
            "1       0   2040       0_부산_축제_문화_행사        [부산, 축제, 문화, 행사, 코스]   \n",
            "2       1    810    1_부산_코스_대교_다이아몬드     [부산, 코스, 대교, 다이아몬드, 광안]   \n",
            "3       2    229       2_구간_코스_부산_인증      [구간, 코스, 부산, 인증, 해수욕장]   \n",
            "4       3    218       3_축제_부산_단풍_공원        [축제, 부산, 단풍, 공원, 휴먼]   \n",
            "5       4    212       4_사람_부산_사랑_생명        [사람, 부산, 사랑, 생명, 생각]   \n",
            "6       5     66      5_청산_청산도_슬로_버스      [청산, 청산도, 슬로, 버스, 범바위]   \n",
            "7       6     41     6_투데이_아시아_축제_개최      [투데이, 아시아, 축제, 개최, 보내]   \n",
            "8       7     40       7_촬영_주최_행사_사진        [촬영, 주최, 행사, 사진, 한국]   \n",
            "9       8     34       8_보내_행사_이동_촬영        [보내, 행사, 이동, 촬영, 출장]   \n",
            "10      9     24      9_코스_몽골_올레_둘레길       [코스, 몽골, 올레, 둘레길, 공원]   \n",
            "11     10     24  10_자전거_서울_페스티벌_광화문    [자전거, 서울, 페스티벌, 광화문, 터널]   \n",
            "12     11     22      11_축제_하늘_장승_공원        [축제, 하늘, 장승, 공원, 청산]   \n",
            "13     12     19     12_호미_바위_코스_둘레길       [호미, 바위, 코스, 둘레길, 해안]   \n",
            "14     13     17              13____                  [, , , , ]   \n",
            "15     14     14    14_둘레길_해안_호미_북한산     [둘레길, 해안, 호미, 북한산, 호미곶]   \n",
            "16     15     12  15_제주_다리_브릿지_다이아몬드  [제주, 다리, 브릿지, 다이아몬드, 출렁다리]   \n",
            "17     16      6      16_러브_페루_사랑_회원        [러브, 페루, 사랑, 회원, 가족]   \n",
            "18     17      6      17_기후_호수_고양_탄소        [기후, 호수, 고양, 탄소, 위기]   \n",
            "19     18      6     18_하늘_공원_월드컵_억새       [하늘, 공원, 월드컵, 억새, 항재]   \n",
            "\n",
            "                                  Representative_Docs  \n",
            "0   [아름답거나추하거나 아름답거나추하거나 39개의 글 아름답거나추하거나 목록열기 제2회...  \n",
            "1   [cafe:soso day by day 8개의 글 day by day 목록열기 부산...  \n",
            "2   [안녕하세요 오늘은 지난주 주말에 진행한 따끈따끈한 축제 후기 2024 다이아몬드브...  \n",
            "3   [갈맷길을 따라 부산을 한 바퀴 돌며 부산의 모든 것을 느껴보는 일주일 동안의 걷기...  \n",
            "4   [푹푹 찌는 무더위로 힘들어했던 때가 엊그제 같은데 어느덧 서늘한 가을의 계절이 성...  \n",
            "5   [#안녕하세요!! 오랜만에 돌아왔습니다!! 요즘 몸도 아프고 #비지니스가 절 괴롭혀...  \n",
            "6   [청산도 숙소 : 똘이 민박 (입도 첫날) 청산도 숙소는 일부러 주요 관광지가 몰려...  \n",
            "7   [블로그 공지 목록 공지글 글 제목 작성일 공지 MEXC 친구초대 이벤트, 1명 초...  \n",
            "8   [ⓒ photographer Seo Chan Woo 행사촬영, 출장촬영, 행사사진,...  \n",
            "9   [portfolio portfolio 85개의 글 portfolio 목록열기 201...  \n",
            "10  [2022년이 3개월 남은 지금, 갑자기 올해 안에 갈맷길을 완보하기로 마음 먹었다...  \n",
            "11  [자전거로, 두발로 자전거로, 두발로 69개의 글 자전거로, 두발로 목록열기 (안내...  \n",
            "12  [청양 특유의 정체성을 담아내는 전국 최고 수준의 민속축제 #청양칠갑산장승문화축제 ...  \n",
            "13  [탐방일자 : 2023.5.10 호미반도해안둘레길은 한반도 최동단지역으로 영일만을 ...  \n",
            "14                  [본문 크롤링 실패, 본문 크롤링 실패, 본문 크롤링 실패]  \n",
            "15  [조금 늦었지만 2024년 등산을 정리해봤습니다. 2024 0101 아차산 7.8 ...  \n",
            "16  [#국제걷기축제 #다이아몬드브릿지 #다이아몬드브릿지국제걷기축제 #다이아몬드브릿지걷기...  \n",
            "17  [지구 반대편에서 이어진 사랑의 발걸음으로 심장병 어린이. 장애아동 도와 어머니 사...  \n",
            "18  [지난 9월 11일 서울시에서는 <기후동행카드>를 내놓는다고 발표했는데요. 드디어 ...  \n",
            "19  [서울에서 걷기 좋은 길 하늘공원과 노을 공원 난초와 지초가 많아서 난지도라 불렸고...  \n"
          ]
        }
      ],
      "source": [
        "# 토픽 정보 확인\n",
        "print(model.get_topic_info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IvgoW1ryb4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "644180cd-8e02-462c-95b4-9803111db53d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c1181b1a-ae5a-4846-825a-8612e249b0de\", \"topic_barchart.html\", 4574698)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 분석 결과가 HTML 파일로 다운로드되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# Topic을 대표하는 상위 단어 5개씩 보여줌\n",
        "fig = model.visualize_barchart(top_n_topics=25)\n",
        "fig.write_html(\"topic_barchart.html\")\n",
        "files.download(\"topic_barchart.html\")\n",
        "\n",
        "print(\"모든 분석 결과가 HTML 파일로 다운로드되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "rSv6UpqVCYZC",
        "outputId": "327679c7-00a9-4714-eef1-8777723aad67"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_75cffdaf-eb5e-450e-8f25-7c0d0ea50d57\", \"topic_visualization.html\", 4577580)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_e2828e47-ac03-4268-b72e-80532e63a9fb\", \"topic_distribution.html\", 4568479)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_846f0af4-ffb5-411a-bda5-a1c0289186dd\", \"topic_hierarchy.html\", 4572545)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_eb72b435-35c2-41d2-a124-65539995b1fd\", \"topic_barchart.html\", 4569898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_89a211af-c912-46ac-8168-382738beb781\", \"topic_heatmap.html\", 4573818)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a61b3516-146c-44eb-af89-b3327585bec8\", \"topic_term_rank.html\", 4577770)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 분석 결과가 HTML 파일로 다운로드되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# 분류된 토픽에 대한 시각화(버블 차트)\n",
        "fig = model.visualize_topics()\n",
        "fig.write_html(\"topic_visualization.html\")\n",
        "files.download(\"topic_visualization.html\")\n",
        "\n",
        "# 특정 Document에 대해서 Topic별 Probabilities를 확인\n",
        "fig = model.visualize_distribution(probs[200], min_probability=0.015)\n",
        "fig.write_html(\"topic_distribution.html\")\n",
        "files.download(\"topic_distribution.html\")\n",
        "\n",
        "# Topic 별 Hierarchy를 보여줌\n",
        "fig = model.visualize_hierarchy(top_n_topics=50)\n",
        "fig.write_html(\"topic_hierarchy.html\")\n",
        "files.download(\"topic_hierarchy.html\")\n",
        "\n",
        "# Topic을 대표하는 상위 단어 5개씩 보여줌\n",
        "fig = model.visualize_barchart(top_n_topics=5)\n",
        "fig.write_html(\"topic_barchart.html\")\n",
        "files.download(\"topic_barchart.html\")\n",
        "\n",
        "# Topic간 유사도를 Cosine Similarity로 계산 후 Heatmap으로 표현\n",
        "fig = model.visualize_heatmap(n_clusters=20, width=1000, height=1000)\n",
        "fig.write_html(\"topic_heatmap.html\")\n",
        "files.download(\"topic_heatmap.html\")\n",
        "\n",
        "# Topic내 대표하는 단어들에 대해서 c-tf-idf로 계산해서 각 단어가 Topic에서 차지하는 중요도를 계산했던 것을 Rank 순대로 보여줌\n",
        "fig = model.visualize_term_rank()\n",
        "fig.write_html(\"topic_term_rank.html\")\n",
        "files.download(\"topic_term_rank.html\")\n",
        "\n",
        "print(\"모든 분석 결과가 HTML 파일로 다운로드되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9e27cG-_zD1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from umap import UMAP\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def create_enhanced_topic_cluster_visualization(model, docs):\n",
        "    # Get the underlying SentenceTransformer model\n",
        "    sentence_model = model.embedding_model.embedding_model\n",
        "\n",
        "    # Extract document embeddings using the SentenceTransformer model\n",
        "    embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
        "\n",
        "    # UMAP을 사용하여 2차원으로 축소\n",
        "    umap_model = UMAP(n_neighbors=15, n_components=2, min_dist=0.1, metric='cosine')\n",
        "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
        "\n",
        "    # 결과 정규화 (시각화를 위해)\n",
        "    scaler = MinMaxScaler()\n",
        "    umap_embeddings = scaler.fit_transform(umap_embeddings)\n",
        "\n",
        "    # 토픽 할당\n",
        "    topics, _ = model.transform(docs)\n",
        "\n",
        "    # 토픽 정보 가져오기\n",
        "    topic_info = model.get_topic_info()\n",
        "\n",
        "    # Plotly를 사용한 산점도 생성\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # 색상 팔레트 정의\n",
        "    colors = [\n",
        "        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
        "        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'\n",
        "    ]\n",
        "\n",
        "    # 각 토픽에 대해 점 추가\n",
        "    for i, topic in enumerate(set(topics)):\n",
        "        if topic != -1:  # -1은 미분류 토픽\n",
        "            topic_name = topic_info[topic_info['Topic'] == topic]['Name'].values[0]\n",
        "            mask = np.array(topics) == topic\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=umap_embeddings[mask, 0],\n",
        "                y=umap_embeddings[mask, 1],\n",
        "                mode='markers',\n",
        "                name=f'Topic {topic}: {topic_name}',\n",
        "                marker=dict(\n",
        "                    size=6,\n",
        "                    color=colors[i % len(colors)],\n",
        "                    line=dict(width=1, color='DarkSlateGrey'),\n",
        "                    opacity=0.7\n",
        "                ),\n",
        "                text=[f\"Document {i}<br>Topic: {topic}<br>{topic_name}\" for i in np.where(mask)[0]],\n",
        "                hoverinfo='text'\n",
        "            ))\n",
        "\n",
        "    # 레이아웃 설정\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': \"Enhanced Visualization of Topic Clusters\",\n",
        "            'y':0.95,\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top',\n",
        "            'font': dict(size=24, family=\"Arial, sans-serif\")\n",
        "        },\n",
        "        xaxis_title=\"UMAP Dimension 1\",\n",
        "        yaxis_title=\"UMAP Dimension 2\",\n",
        "        legend_title=\"Topics\",\n",
        "        width=1200,\n",
        "        height=800,\n",
        "        plot_bgcolor='rgba(240,240,240,0.5)',\n",
        "        paper_bgcolor='white',\n",
        "        font=dict(family=\"Arial, sans-serif\"),\n",
        "        legend=dict(\n",
        "            itemsizing='constant',\n",
        "            font=dict(size=10),\n",
        "            borderwidth=1\n",
        "        ),\n",
        "        margin=dict(l=50, r=50, t=80, b=50),\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', zeroline=False)\n",
        "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', zeroline=False)\n",
        "\n",
        "    # HTML 파일로 저장\n",
        "    fig.write_html(\"enhanced_topic_clusters_visualization.html\")\n",
        "    files.download(\"enhanced_topic_clusters_visualization.html\")\n",
        "    print(\"향상된 토픽 클러스터 시각화가 'enhanced_topic_clusters_visualization.html' 파일로 저장되었습니다.\")\n",
        "\n",
        "# 함수 호출\n",
        "create_enhanced_topic_cluster_visualization(model, preprocessed_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S5ue_rxtrCoN",
        "outputId": "356e9b25-be31-46e9-bc72-dd00337e3c67"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_6d947603-bac0-4a03-b096-1b02fcb0c12b\", \"c_tf_idf_values.csv\", 86198)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c-TF-IDF 값이 'c_tf_idf_values.csv' 파일로 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# c-TF-IDF 값 추출\n",
        "c_tf_idf = model.c_tf_idf_\n",
        "words = model.vectorizer_model.get_feature_names_out()\n",
        "\n",
        "# 모든 토픽에 대한 c-TF-IDF 값 합산\n",
        "total_c_tf_idf = c_tf_idf.toarray().sum(axis=0)\n",
        "\n",
        "# 결과를 데이터프레임으로 변환\n",
        "c_tf_idf_df = pd.DataFrame({'단어': words, 'c-TF-IDF': total_c_tf_idf})\n",
        "c_tf_idf_df = c_tf_idf_df.sort_values('c-TF-IDF', ascending=False)\n",
        "\n",
        "# CSV 파일로 저장\n",
        "c_tf_idf_df.to_csv('c_tf_idf_values.csv', index=False, encoding='utf-8-sig')\n",
        "files.download('c_tf_idf_values.csv')\n",
        "\n",
        "print(\"c-TF-IDF 값이 'c_tf_idf_values.csv' 파일로 저장되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "collapsed": true,
        "id": "4aBVdKFOfAtu",
        "outputId": "331754f9-ea9b-4918-ad14-300e9fea87d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         단어   빈도수       퍼센트\n",
            "1627     시간  2409  2.615522\n",
            "959      마음  1985  2.155172\n",
            "1476     생각  1899  2.061800\n",
            "2728  템플스테이  1592  1.728481\n",
            "122      감사  1569  1.703509\n",
            "1604     스님  1362  1.478763\n",
            "1037     명상   805  0.874012\n",
            "671      다시   701  0.761096\n",
            "217      경험   688  0.746982\n",
            "2619     처음   643  0.698124\n",
            "2896     행복   629  0.682924\n",
            "1408     사람   593  0.643837\n",
            "2633     체험   552  0.599323\n",
            "997      말씀   549  0.596065\n",
            "2856     함께   521  0.565665\n",
            "2260     자신   460  0.499435\n",
            "1557     소리   447  0.485321\n",
            "2224     일상   435  0.472292\n",
            "440      기회   432  0.469035\n",
            "366     그리고   413  0.448406\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_d8e78524-3617-4891-bdee-fa5dc1ce42f4\", \"word_frequencies.csv\", 93295)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 단어 빈도수 계산\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, max_features=3000, stop_words=korean_stop_words)\n",
        "X = vectorizer.fit_transform(preprocessed_documents)\n",
        "\n",
        "# 단어 목록과 빈도수\n",
        "word_freq = X.sum(axis=0).A1\n",
        "words = vectorizer.get_feature_names_out()\n",
        "word_count = pd.DataFrame({'단어': words, '빈도수': word_freq})\n",
        "\n",
        "# 빈도수에 따른 퍼센트 계산\n",
        "word_count['퍼센트'] = (word_count['빈도수'] / word_count['빈도수'].sum()) * 100\n",
        "\n",
        "# 빈도수에 따라 정렬\n",
        "word_count = word_count.sort_values(by='빈도수', ascending=False)\n",
        "\n",
        "# 상위 20개의 단어 확인\n",
        "print(word_count.head(20))\n",
        "\n",
        "# 전체 단어의 빈도수와 퍼센트를 CSV로 저장해서 다운로드\n",
        "word_count.to_csv('word_frequencies.csv', index=False, encoding='utf-8-sig')\n",
        "files.download('word_frequencies.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mOTb0aXCMgZ9",
        "outputId": "7fb7d89c-f4f1-4beb-af4b-a04781a73e00"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_f4ddfbac-ae5b-4ef2-85e3-71c52175eb5b\", \"enhanced_topic_clusters_visualization.html\", 4739134)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "향상된 토픽 클러스터 시각화가 'enhanced_topic_clusters_visualization.html' 파일로 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from umap import UMAP\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "\n",
        "def create_enhanced_topic_cluster_visualization(model, docs):\n",
        "    # Get the underlying SentenceTransformer model\n",
        "    sentence_model = model.embedding_model.embedding_model\n",
        "\n",
        "    # Extract document embeddings using the SentenceTransformer model\n",
        "    embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
        "\n",
        "    # UMAP을 사용하여 2차원으로 축소\n",
        "    umap_model = UMAP(n_neighbors=15, n_components=2, min_dist=0.1, metric='cosine')\n",
        "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
        "\n",
        "    # 결과 정규화 (시각화를 위해)\n",
        "    scaler = MinMaxScaler()\n",
        "    umap_embeddings = scaler.fit_transform(umap_embeddings)\n",
        "\n",
        "    # 토픽 할당\n",
        "    topics, _ = model.transform(docs)\n",
        "\n",
        "    # 토픽 정보 가져오기\n",
        "    topic_info = model.get_topic_info()\n",
        "\n",
        "    # 색상 팔레트 생성\n",
        "    color_palette = px.colors.qualitative.Bold\n",
        "\n",
        "    # Plotly를 사용한 산점도 생성\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # 각 토픽에 대해 점 추가\n",
        "    for i, topic in enumerate(set(topics)):\n",
        "        if topic != -1:  # -1은 미분류 토픽\n",
        "            topic_name = topic_info[topic_info['Topic'] == topic]['Name'].values[0]\n",
        "            mask = np.array(topics) == topic\n",
        "            color = color_palette[i % len(color_palette)]\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=umap_embeddings[mask, 0],\n",
        "                y=umap_embeddings[mask, 1],\n",
        "                mode='markers',\n",
        "                name=f'Topic {topic}: {topic_name}',\n",
        "                marker=dict(\n",
        "                    size=8,\n",
        "                    color=color,\n",
        "                    symbol='circle',\n",
        "                    line=dict(width=1, color='DarkSlateGrey')\n",
        "                ),\n",
        "                text=[f\"Document {i}<br>Topic: {topic}<br>{topic_name}\" for i in np.where(mask)[0]],\n",
        "                hoverinfo='text'\n",
        "            ))\n",
        "\n",
        "    # 레이아웃 설정\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': \"Visualization of Topic Clusters\",\n",
        "            'y':0.95,\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top',\n",
        "            'font': dict(size=24, color='DarkSlateGrey')\n",
        "        },\n",
        "        xaxis_title=\"UMAP Dimension 1\",\n",
        "        yaxis_title=\"UMAP Dimension 2\",\n",
        "        legend_title=\"Topics\",\n",
        "        width=1200,\n",
        "        height=800,\n",
        "        plot_bgcolor='rgb(250,250,250)',\n",
        "        legend=dict(\n",
        "            itemsizing='constant',\n",
        "            font=dict(size=10),\n",
        "            borderwidth=1\n",
        "        ),\n",
        "        margin=dict(l=50, r=50, t=80, b=50),\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
        "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
        "\n",
        "    # HTML 파일로 저장\n",
        "    fig.write_html(\"enhanced_topic_clusters_visualization.html\")\n",
        "    files.download(\"enhanced_topic_clusters_visualization.html\")\n",
        "    print(\"향상된 토픽 클러스터 시각화가 'enhanced_topic_clusters_visualization.html' 파일로 저장되었습니다.\")\n",
        "\n",
        "# 함수 호출\n",
        "create_enhanced_topic_cluster_visualization(model, preprocessed_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "collapsed": true,
        "id": "sEP2isYrINdh",
        "outputId": "471417d1-2a15-4f62-bfc5-78d98d52ccf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.39)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (3.2.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.5)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (10.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.1)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_eb9a381d-1700-4a01-972f-0d8ce1f7fb12\", \"topic_network.html\", 4571465)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install bertopic\n",
        "!pip install plotly\n",
        "!pip install networkx\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "from bertopic import BERTopic # Import the BERTopic class\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def create_topic_network(model, n_topics=10):\n",
        "    topic_info = model.get_topic_info().head(n_topics)\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for _, row in topic_info.iterrows():\n",
        "        G.add_node(row['Topic'], size=row['Count'])\n",
        "\n",
        "    # Get topic embeddings\n",
        "    topic_embeddings = model.topic_embeddings_\n",
        "\n",
        "    for i in range(len(topic_info)):\n",
        "        for j in range(i+1, len(topic_info)):\n",
        "            # Calculate cosine similarity between topic embeddings\n",
        "            similarity = cosine_similarity(topic_embeddings[topic_info.iloc[i]['Topic']].reshape(1, -1),\n",
        "                                           topic_embeddings[topic_info.iloc[j]['Topic']].reshape(1, -1))[0][0]\n",
        "\n",
        "            if similarity > 0.2:  # 유사도 임계값 설정\n",
        "                G.add_edge(topic_info.iloc[i]['Topic'], topic_info.iloc[j]['Topic'], weight=similarity)\n",
        "\n",
        "    pos = nx.spring_layout(G)\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    for edge in G.edges():\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=0.5, color='#888'), hoverinfo='none', mode='lines')\n",
        "\n",
        "    node_x = [pos[node][0] for node in G.nodes()]\n",
        "    node_y = [pos[node][1] for node in G.nodes()]\n",
        "\n",
        "    node_trace = go.Scatter(x=node_x, y=node_y, mode='markers+text', hoverinfo='text',\n",
        "                            marker=dict(showscale=True, colorscale='YlGnBu', size=10, colorbar=dict(thickness=15, title='Node Connections')),\n",
        "                            text=[f\"Topic {node}\" for node in G.nodes()], textposition=\"top center\")\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(showlegend=False, hovermode='closest',\n",
        "                                     margin=dict(b=20,l=5,r=5,t=40)))\n",
        "    fig.write_html(\"topic_network.html\")\n",
        "\n",
        "    # Assuming 'files' is from google.colab\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(\"topic_network.html\")\n",
        "    except ImportError:\n",
        "        print(\"Could not import 'files' from google.colab. Skipping download.\")\n",
        "\n",
        "create_topic_network(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UHT1U4HPIsqF",
        "outputId": "bd351bfb-ce56-404d-a25a-f903afb4c2c7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c3847f9a-82da-4f5d-87ba-c4d364891397\", \"c_tf_idf_heatmap.html\", 4569283)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c-TF-IDF 히트맵이 'c_tf_idf_heatmap.html' 파일로 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def visualize_c_tf_idf_html(model, n_topics=5, n_words=10):\n",
        "    topic_info = model.get_topic_info()\n",
        "\n",
        "    # 상위 n_topics 개의 토픽에 대해 상위 n_words 개의 단어와 c-TF-IDF 값 추출\n",
        "    data = []\n",
        "    for topic in topic_info['Topic'][:n_topics]:\n",
        "        words, values = zip(*model.get_topic(topic)[:n_words])\n",
        "        data.extend([(topic, word, value) for word, value in zip(words, values)])\n",
        "\n",
        "    # DataFrame 생성\n",
        "    df = pd.DataFrame(data, columns=['Topic', 'Word', 'c-TF-IDF'])\n",
        "\n",
        "    # 피벗 테이블 생성\n",
        "    pivot_df = df.pivot(index='Word', columns='Topic', values='c-TF-IDF')\n",
        "\n",
        "    # Plotly를 사용한 히트맵 생성\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "                    z=pivot_df.values,\n",
        "                    x=pivot_df.columns,\n",
        "                    y=pivot_df.index,\n",
        "                    colorscale='YlOrRd',\n",
        "                    hoverongaps = False))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='c-TF-IDF Values Heatmap',\n",
        "        xaxis_title='Topics',\n",
        "        yaxis_title='Words',\n",
        "        width=900,\n",
        "        height=700\n",
        "    )\n",
        "\n",
        "    # HTML 파일로 저장\n",
        "    fig.write_html(\"c_tf_idf_heatmap.html\")\n",
        "    files.download(\"c_tf_idf_heatmap.html\")\n",
        "\n",
        "    print(\"c-TF-IDF 히트맵이 'c_tf_idf_heatmap.html' 파일로 저장되었습니다.\")\n",
        "\n",
        "# 함수 호출\n",
        "visualize_c_tf_idf_html(model, n_topics=5, n_words=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojm0NgvwKnyB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMKYDIB7RAHFIIIE+d2Na/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}